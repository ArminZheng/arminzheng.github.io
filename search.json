[{"title":"Gallery","url":"/2021/08/18/Gallery/","content":"搁置了好几个月，终于决定使用Github Action来让我的博客复活了\n","categories":["study"],"tags":["笔记"]},{"title":"GitHub Action","url":"/2022/01/11/GitHub-Action/","content":"Action的创建方式1：在项目根部，创建以下文件夹和文件\n# 这里以我的 hexo 博客自动部署举例.github└── workflows    └── hexo-deploy.yml\n\n方式2：在网页端的action上按照提示进行\nAction的编排编排文件的结构Action 主要由三部分构成：name、on 和 jobs\nname: 叫什么（如果忽略会默认为yml的文件名）\non: 作用在什么地方（触发点）\njobs: 触发后干什么\n—— name0\n—— on push branches master\n—— Jobs name1 runs-on steps name run env uses\nyml 文件实例# 部分1name: 显示在action的名字# 部分2on: # 绑定的地方  push: # 绑定推送    branches: # 绑定推送的分支      - master# 部分3jobs:  # 干活标识 自定义  build-and-deploy:    # 干活内容    # 运行服务器镜像（总共有几种选择，官网上可查）    runs-on: ubuntu-latest    # 运行条件判断    if: github.event.repository.owner.id == github.event.sender.id   \t# 运行步骤   \tsteps:   \t  - name: Checkout # 步骤标识，自定义   \t    # 这里是引用的意思   \t    # actions是官方定义的类似一个账号   \t    # checkout是仓库名   \t    # @后面是分支，也可以是 @v1 代表git标签   \t    uses: actions/checkout@master   \t        - name: Setup Node.js        uses: actions/setup-node@v1        with:          node-version: &#x27;12&#x27;           \t  - name: Setup Hexo        # 环境变量 通常用来获取仓库设置的secrets（里面可能是账号的密码或者公/私钥之类的）        env:          ACTION_DEPLOY_KEY: $&#123;&#123; secrets.DEPLOY &#125;&#125;        # 运行命令        run: |          mkdir -p ~/.ssh          echo &quot;$ACTION_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa          chmod 700 ~/.ssh          chmod 600 ~/.ssh/id_rsa          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts          git config --global user.name &quot;$&#123;&#123; vars.USER_NAME &#125;&#125;&quot;          git config --global user.email &quot;$&#123;&#123; vars.USER_EMAIL &#125;&#125;&quot;          npm install hexo-cli -g          npm install      - name: Deploy        run: |          hexo clean          hexo deploy -g\n\n可以看到 jobs 下面是一个 标识，再下面是 steps，再再下面才是执行 命令。总共有 3 层。\nAction在不同仓库之间访问和推送我们可以本地生成一对公/私钥，保存下来。\nssh-keygen -t rsa -C &quot;Comment&quot; -f file_name\n\n在私有仓库设置 Secrets，将私钥复制进去，然后在 action 里面，通过标识进行引用。命令里面将私钥复制到本地 .ssh目录下。\n在公有仓库设置 Deploy keys，将公钥复制进去，然后私有仓库的action就可以部署到这个公有仓库了。\naction 代表了一个独立的服务器环境，你可以在这里进行一系列的流程作业。\n","categories":["自动部署"],"tags":["git","github","devops"]},{"title":"Source Map","url":"/2022/04/26/Source%20Map/","content":"简述通常 js 脚本 在通过诸如 webpack 等打包压缩后，会变成仅一行的 js 文件，这样带来几点好处：\n\n压缩，减少体积（jquery.min.js 能压缩十倍文件大小）\n多个文件合并成一个，能在第一次访问时候减少 js 文件请求数\n将其他脚本编译成 JavaScript 脚本供页面使用\n\n但同时也带了一个新的问题：我们的 debug，诸如 console.log 和 报错信息 等，控制台无法输出正确的源码位置。由此 Source Map 应运而生。\nSource Map 就是 源码 和对应 压缩成仅一行后的 js 代码 的对照文件\n源码转换\n压缩后：jquery.min.js 例子\n\nSource Map：jquery.min.map 例子\n\n\n可以看到 如1所示 压缩后的 jquery.min.js 文件有两行：一行 js 脚本 + 一行注释\n其中第二行注释内容：\n//@ sourceMappingURL=jquery.min.map\n\n这是一种固定格式：告诉我们将 URL 链接中的 jquery.min.js 替换为 jquery.min.map，即可得到 Source Map 文件。这不关是告诉我们，同时也是告诉浏览器如何输出正确的源码位置。\nSource Map 文件格式固定由一个对象组成，里面包含 6 个属性（5 个必填）\n&#123;  // 版本  version : 3,  // 转换后的文件名  file: &quot;out.js&quot;,  // 转换前的文件所在的目录。如果与转换前的文件在同一目录，该项为空或忽悠  sourceRoot : &quot;&quot;,  // 转换前的文件。该项是一个数组，表示可能存在多个文件合并  sources: [&quot;foo.js&quot;, &quot;bar.js&quot;],  // 转换前的所有变量名和属性名  names: [&quot;src&quot;, &quot;maps&quot;, &quot;are&quot;, &quot;fun&quot;],  // 记录位置信息的字符串，也是实际上进行转换的映射信息  mappings: &quot;AAgBC,SAAQ,CAAEA&quot;&#125;\n\nSource Map 对象的 mappings 属性mappings 属性仅包含一段字符串。里面的内容需要进行层次划分来达到，横纵坐标转换。\n&#123;  ...  mappings: &quot;AAgBC,SAAQ,CAAEA&quot;&#125;\n\n分隔符有：（;）分号（,）逗号（总共两种）\n第一次分割是用（;）分号，对应压缩后的行数（压缩目的是节省，所以压缩后大多为一行，也会出现多行的情况，但总是从第一行开始，前面不会有空行）第一行的内容结束，分号隔开，接上第二行\n第二次分割使用（,）逗号，对应压缩后的位置。通常一个报错信息会指出一个错误开始的地方，开始的地方到语句结束的地方就叫一个位置。(注意：这一层不表示压缩后的对应列数，仅大概位置)\n最后分割为一段字符串单位后，就进行位置转换了。\n如 AAgBC 这样的字符串，是按照 VLQ 编码（Variable-length Quantity）表示的，表示该位置对应的转换前的源码位置。\nVLQ 编码VLQ 编码字段通常有 5 个字符（4 个字符、6 个字符）\n\n从左边算起:\n第一位表示这个位置在压缩后的代码的第几列\n第二位表示这个位置属于 sources属性 中的哪一个文件\n第三位表示这个位置属于转换前代码的第几行\n第四位表示这个位置属于转换前代码的第几列\n第五位表示这个位置属于 names属性中的哪一个变量\n\n\n\n由于每个字符使用 6 个两进制位，所以字段内容的对应值与 Base64 相似，具体的对应参数可以查阅 VLQ 编码\n\n","categories":["study"],"tags":["笔记"]},{"title":"Hello World","url":"/2020/06/08/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","tags":["note"]},{"title":"互联网协议","url":"/2020/08/08/%E4%BA%92%E8%81%94%E7%BD%91%E5%8D%8F%E8%AE%AE/","content":"总体思路\n网络接口层\n\n0、1 电信号\n以太网协议\n帧 Frame（以太数据包）:\n标头 head 18 B （头部 14 + 尾部：冗余校验码 FCS 4）Frame check sequence\n数据 data 46 ~ 1500 B （数据很长就分多个帧）（总共 64 ~ 1518 B）\n前同步码：用来使接收端的适配器在接收 MAC 帧时能够迅速调整时钟频率，使它和发送端的频率相同。前同步码为 7 个字节，1 和 0 交替。\n帧开始定界符：帧的起始符，为 1 个字节。前 6 位 1 和 0 交替，最后的两个连续的 1 表示告诉接收端适配器：“帧信息要来了，准备接收”。\n\n\nMAC 地址：48 位 = 6 B = 12 个十六进制数表示（6 对），前 6 个十六进制（3 对）是厂家编号，后 6 个（3 对）是该厂家的网卡流水号（用来定位网卡和数据包的路径）\nARP 协议：网卡知道网卡的 MAC 地址\n所查询主机的 IP，在对方 MAC 地址一栏填的是 FF:FF:FF:FF，表示这是一个广播\n它所在子网络的每一台主机，都会收到这个数据包，从中取出 IP 地址，与自身的 IP 地址进行比较。如果两者相同，都做出回复，向对方报告自己的 MAC 地址，否则就丢弃这个包。\n\n\n\n\n网络层\n\n网络地址（子网络）\nIP 协议（32 位）\n子网掩码（ip AND 掩码 == 网络部分）\n\n\nIP 数据包\nHead: 20~60\nData: 65535 - Head\n标头和数据放进帧的数据里面（可以分多个帧）\n\n\n“网络层”的功能是建立”主机到主机”的通信。\n\n\n传输层\n\n端口：不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。\n\n“传输层”的功能，就是建立”端口到端口”的通信。\n\n只要确定主机和端口，我们就能实现程序之间的交流。主机+端口，叫做”套接字”（socket）。\n\nUDP 协议\n\nUDP 数据包，也是由”标头”和”数据”两部分组成。\n“标头”部分主要定义了发出端口和接收端口 8 字节 Bit\n“数据”部分就是具体的内容。总长度不超过 65535 字节 Bit\n\n\n\n以太数据包 头 + IP 数据包 头 + UDP 数据包 头\n\n\nTCP 协议\n\n有确认机制的 UDP 协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。\nTCP 数据包和 UDP 数据包一样，都是内嵌在 IP 数据包的”数据”部分。TCP 数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常 TCP 数据包的长度不会超过 IP 数据包的长度，以确保单个 TCP 数据包不必再分割。\n\n\n\n\n应用层\n\nTCP 协议可以为各种各样的程序传递数据，比如 Email、WWW、FTP 等等。那么，必须有不同协议规定电子邮件、网页、FTP 数据的格式，这些应用程序协议就构成了”应用层”。\n\n\n\n用户角度\n以太网标头需要知道：\n\n对方的 MAC 地址\n对方的 IP 地址\n\n\n但不在同一子网，无法知道对方 MAC 地址，必须通过 Gateway 网关转发\n\n上网设置\n\n静态 IP 地址\n本机的 IP 地址　　* 子网掩码\n网关的 IP 地址\nDNS 的 IP 地址\n\n\n\n\n动态 IP 地址\nDHCP 协议（应用层协议）\n不知道对面的 MAC 地址：就设置对方 MAC 地址为广播地址（FF-FF-FF-FF-FF-FF）\n我方对方的 IP 地址都不知道：就设置我方：0.0.0.0；对方 255.255.255.255\n双方端口：协议规定好了，我方：68，对方：67\n由于 MAC 地址是广播，每个都收到，但 IP 地址是 0….、255….DHCP 知道 ”这是发给我的“ ，其他计算机都丢弃。\nDHCP 服务器读出数据，分配好 IP，发回一个 DHCP 响应包\n结构为：以太网标头的 MAC 地址是双方的网卡地址，IP 标头的 IP 地址是 DHCP 服务器的 IP 地址（发出方）和 255.255.255.255（接收方），UDP 标头的端口是 67（发出方）和 68（接收方），分配给请求端的 IP 地址和本网络的具体参数则包含在 Data 部分。\n计算机收到响应包，就知道了自己的 IP 地址、子网掩码、网关地址、DNS 服务器等参数。\n\n\n\n\n\n\n\n\n实例：访问一个网站\n\nDNS 协议：已知 DNS 服务器为 8.8.8.8，于是我们向这个地址发送一个 DNS 数据包，53 端口。网址会转换为 IP 地址，得到响应，我们就知道对方的 IP 地址。\n\n子网掩码，判断是否为一个网段，不为一个网段，就必须通过网关的转发，于是接收方 MAC 地址将是本机网关的 MAC 地址。\n\n应用层协议：HTTP 协议。请求头请求体等，假定长度为 4960 字节，将会被嵌入到 TCP 数据包中。\n\nTCP 协议：接收方默认端口为 80 端口，本机端口是一个随机生成的 1024~65535 之间的整数，假定为 51755。加入一个 TCP 数据包 20 字节，总大小+20，4980 字节\n\nIP 协议：TCP 数据包嵌入 IP 数据包，会设置双方 IP 地址。IP 数据包的标头长度为 20 字节，加上嵌入的 TCP 数据包，总长度变为 5000 字节。\n\n以太网协议：IP 数据包嵌入以太数据包，需要设置 MAC 地址，设置本机 MAC 地址，接收方设置为网关 192.168.1.1 的 MAC 地址（通过 ARP 协议得到，也就是广播获得的 MAC 地址）\n\n服务端响应\n\n通过多个网关转发，网站服务器收到 4 个以太网数据包。\n根据 IP 标头的序号，将 4 个包拼起来，读取出完整的 TCP 数据包，读出请求，作出响应，再用 TCP 协议发回来。\n本机收到响应后，就可以将网页显示出来了，通信完成。\n\n\n\n\n\n\n\n三次握手\nSYN(synchronous 建立连接) （标志位 1 bit） 最后一次握手 SYN 不为 1 是不消耗序号的\nACK(acknowledgement 确认)\nPSH(push 传送)\nFIN(finish 结束)\nRST(reset 重置)\nURG(urgent 紧急)\n\n以上是标志位\n\n以下是序号和确认号\n\nSequence number (seq 序号)\nAcknowledge number (AN 确认号) 是对方的序号。如果占用己方序号和对方确认号都加一\nack 确认报文段不占用序号，只有三种情况需要占用\n1、syn=1\n2、fin=1\n3、携带数据一个字节占用一个序号\n\n\n序号和确认号是相对的，seq 表示上次发送的数据量，an 代表上次接收的数据量（都是累加还算上初始值）\n[ip 首部 + ip 数据部分{ tcp 首部 + 数据部分 } ]\nip 数据部分包含 tcp 包（8位倍数的可选项，如果未达到 32 则进行填充）\n\n\n\n\n\n","categories":["study"],"tags":["笔记"]},{"title":"使用 oh-my-zsh 的 git 别名","url":"/2022/01/18/%E4%BD%BF%E7%94%A8%20oh-my-zsh%20%E7%9A%84%20git%20%E5%88%AB%E5%90%8D/","content":"1. 安装 oh-my-zsh安装oh-my-zsh 之后会默认设置一些常用命令的快捷别名缩写，熟悉之后可以极大提高我们的效率。\n2. git 操作常用 git 操作的别名，可以使用 $ alias  命令查看全部。\n$ gcmsg=git commit -m$ gst=git status$ gp=git push$ gl=git pull$ ggpush|gpsup=git push --set-upstream origin $(git_current_branch)$ ggpull=git pull origin $(git_current_branch)$ gpr|gup=git pull --rebase$ ga=git add$ gaa=git add --all$ gb=git branch$ gba=git branch -a$ gcl=git clone --recurse-submodule  # 递归拉取自模块，如果没有子模块等同于 git clone$ gco=git checkout$ gcb=git checkout -b$ grh=git reset$ grhh=git reset --hard$ gstall=git stash --all$ gstl=git stash --list$ gstp=git stash pop$ grm=git rm$ grmc=git rm --cached$ grv=git remote -v$ gcf=git config --list\n\n日常使用流程：\n$ gcl # 克隆代码$ # 写代码$ ga .gitignore # 添加忽略文件$ gst # 查看那些改变 status$ gaa # 添加所有文件到暂存区$ gcmsg &quot;提交内容&quot; # 提交代码$ gl # 查看远程是否有更新$ ggpush # 第一次提交，关联上游$ gp # 后续提交使用 gp\n\n特殊操作：\n$ gba # 查看分支(通常是查看所有)$ gcb # 切换分支$ grmc # 删除暂存区的提交 cached$ grhh # 丢弃修改，回滚$ grv # 查看远程仓库地址$ gcf # 查看配置信息(主要是用户名和邮箱)$ gstall # 闪存$ gstp # 闪取$ gstl # 闪存列表\n\n另外还有一些使用率很高的别名作为补充。\n$ md # mkdir -p 创建文件夹$ .. # 代表 cd ..$ ...... # 两个点之后每个点代表一层上级目录，最多5层，也就是6个点$ _ # 下划线代表 sudo\n","categories":["效率"],"tags":["git"]},{"title":"使用注解实现数据字典翻译","url":"/2022/02/03/%E4%BD%BF%E7%94%A8%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%AD%97%E5%85%B8%E7%BF%BB%E8%AF%91/","content":"前言在日常开发中查询单表的情况非常多。这时总会出现表里存的是编码（如部门编号），但却要返回对应的描述（如部门名称）。\n通常一般思路是在 Service 进行关联查询或依赖组件完成。比如 Mybatis 中用 join 语句将 sql 写死，比如 JPA 中在实体类属性字段加上@ManyToOne注解，直接将对象组合起来。\nprivate String orgId;@ManyToOne(fetch = FetchType.EAGER)@JoinColumn(name = &quot;orgId&quot;, insertable = false, updatable = false)private BaseOrg baseOrg;\n\n上面的方式固然简单直接，但是我觉得还不够快，而且过度依赖组件在以后的修改中也会比较麻烦，接下来就由我来提供一种新的思路。\n思路无论是列表还是单个查询，本质上是先找到编码，再去找对应描述，首要条件就是：顺序不能颠倒，我们不能进行预判。所以我们的任务就像一条流水线一样，得到数据进行查询，再返回填充。如果是列表，那就遍历一遍，时间复杂度O(n)。\n而这样一个过程其实是非常模范的，容易提炼出来。我起先的思路是结合Spring的切面来做，可深度考虑后发现切面只能针对方法的调用，而方法的返回值有很多种，单个对象、List以及IPage分页等。放在 set() 方法上也没有办法得到该 set() 对应的实体再填充。后面转换思路写为工具类在所需要的地方进行调用，一切都简单了不少。比如加入到 MP 的分页转换过程中（ IPage &lt;PO&gt; to IPage &lt;VO&gt;）。\n工具类的思路确定了。我们剩下还需要的。1是查询对应的编码所需要的单表查询Service，2是填充的属性名称（如果是Json动态添加一个JsonElement就不需要在VO再加一个属性，但考虑到我们的业务层或许也需要该字段，就添个属性用来存放）。接下来就开工。\n实现注解\n@Dict 包含填充目标属性，和调用的service\n\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)@Documentedpublic @interface Dict &#123;  String target();  String service();&#125;\n\n\n视图对象VO\n\n@Data@NoArgsConstructor@ApiModel(value = &quot;员工VO&quot;, description = &quot;EmployeeVO&quot;)public class EmployeeVO implements Serializable &#123;  /** 名称 */  @ApiModelProperty(&quot;名称&quot;)  private String name;  /** 编号 */  @ApiModelProperty(&quot;编号&quot;)  private String number;  /** 所属机构代码 */  @ApiModelProperty(&quot;所属机构代码&quot;)  @Dict(target = &quot;orgName&quot;, service = &quot;baseOrgService&quot;)  private String orgCode;  /** 所属机构 */  @ApiModelProperty(&quot;所属机构&quot;)  private String orgName;  public EmployeeVO(EmployeePO po) &#123;    this.name = po.getName();    this.number = po.getNumber();    this.orgCode = po.getOrgCode();  &#125;&#125;\n\n\n进行翻译的工具类\n\n@Slf4jpublic class BeanHelpUtils &#123;/// 主要代码 ⬇️  public static &lt;T&gt; void translation(T t)      throws IntrospectionException, InvocationTargetException, IllegalAccessException &#123;    Field[] fields = t.getClass().getDeclaredFields();    for (Field field : fields) &#123;      if (field.isAnnotationPresent(Dict.class)) &#123;        String target = field.getAnnotation(Dict.class).target();        String service = field.getAnnotation(Dict.class).service();        DictService dictService = SpringContextUtil.getBean(service, DictService.class);        if (dictService != null) &#123;          PropertyDescriptor source = new PropertyDescriptor(field.getName(), t.getClass());          Object invoke = source.getReadMethod().invoke(t);          if (invoke instanceof String) &#123;            Object result = dictService.getValue((String) invoke);            PropertyDescriptor targetResult = new PropertyDescriptor(target, t.getClass());            targetResult.getWriteMethod().invoke(t, result);          &#125;        &#125;      &#125;    &#125;  &#125;/// 主要代码 ⬆️  public static &lt;T&gt; void translation(List&lt;T&gt; collect) &#123;    for (T t : collect) &#123;      try &#123;        translation(t);      &#125; catch (IntrospectionException | InvocationTargetException | IllegalAccessException e) &#123;        if (log.isInfoEnabled()) log.info(e.getMessage());        e.printStackTrace();      &#125;    &#125;  &#125;  /** 分页复制 */  public static &lt;T, E&gt; IPage&lt;T&gt; pageTransform(IPage&lt;E&gt; page, Function&lt;E, T&gt; sup) &#123;    if (page == null || page.getRecords() == null) return null;    List&lt;T&gt; collect = page.getRecords().stream().map(sup).collect(Collectors.toList());    translation(collect);    return new Page&lt;T&gt;(page.getCurrent(), page.getSize(), page.getTotal()).setRecords(collect);  &#125;&#125;\n\n\n为了能进行统一调用，写了一个 DictService 字典接口\n\npublic interface DictService &#123;  Object getValue(String key);&#125;\n\n\n实现了字典接口的 OrgService\n\n@Servicepublic class BaseOrgService extends ServiceImpl&lt;BaseOrgMapper, BaseOrgPO&gt; implements DictService &#123;  @Override  public Object getValue(String orgCode) &#123;    BaseOrgPO po =        baseMapper.selectOne(            new QueryWrapper&lt;BaseOrgPO&gt;()                .lambda()                .eq(BaseOrgPO::getOrgCode, orgCode)                .last(&quot;LIMIT 1&quot;));    if (po == null) return null;    return po.getOrgName();  &#125;&#125;\n\n\n获取 \bBean 的工具类，使用了 Spring 的 ApplicationContextAware\n\n@Configurationpublic class SpringContextUtil implements ApplicationContextAware &#123;  public static ApplicationContext applicationContext;  @Override  public void setApplicationContext(@NonNull ApplicationContext applicationContext)      throws BeansException &#123;    SpringContextUtil.applicationContext = applicationContext;  &#125;  public static ApplicationContext getApplicationContext() &#123;    return applicationContext;  &#125;  public static String getProperty(String path) &#123;    return applicationContext.getEnvironment().getProperty(path);  &#125;  public static Object getBean(String name) throws BeansException &#123;    if (applicationContext == null) return null;    return applicationContext.getBean(name);  &#125;  public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException &#123;    if (applicationContext == null) return null;    return applicationContext.getBean(name, requiredType);  &#125;&#125;\n\n\n在所需要的地方应用\n\n// 调用分页转换，自动翻译...IPage&lt;EmployeePO&gt; poPage = employeeMapper.selectPage(page, new QueryWrapper&lt;EmployeePO&gt;().lambda()                .eq(...return BeanHelpUtils.pageTransform(poPage, EmployeeVO::new);// 或直接调用翻译List&lt;EmployeeVO&gt; records = poPage.getRecords();BeanHelpUtils.translation(records);return records;\n\n数据字典缓存由于我一开始提到的是数据字典，其实数据字典通常是一张或者两张表，用来存放编码和对应值，如：\nA表存放：gender ｜ 性别\nB表存放：gender ｜ 1 ｜ 男 、 gender ｜ 2 ｜ 女 ；\n（全部放在一张表也行，可根据数据复杂度而定）\n最后通过单表的字段值 1 来进行数据字典表查找。有时候数据字典会有很多其他别名，如标准码、标准代码，多见于专业领域。\n由于数据字典表的特性，在写入之后，很少会去修改，非常适合结合Redis来进行缓存，提高查询数据。\n我们可以在对应数据字典的Service层接入 Spring Cache + Redis 来进行缓存。\n（完）\n","categories":["灵感"],"tags":["springboot"]},{"title":"函数式编程","url":"/2020/08/08/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/","content":"鲜明的特点\n函数是一等公民，地位与变量同一地位；\n\n只用表达式，不用语句；语句代表执行某种操作，没有返回值，比如I/O操作；从一开始就是为了处理运算（computation），不考虑I/O，实际情况是尽可能限制到最小，保持计算过程的单纯性；\n\n没有副作用；保持独立，所有功能就是返回一个新的值，没有其他行为，尤其修改外部变量；\n\n不修改状态；这意味着状态不能保存在变量中，函数式编程使用递归保存状态。缺点是运行速度比较慢；\n\n引用透明；不依赖外部变量，只依赖输入参数，任何时候参数相同，返回值总是相同的；利于观察和理解的行为；\n\n\n意义\n代码简洁，开发快速；\n接近自然语言，易于理解；\n不依赖，更方便的代码管理；\n易于并发编程（concurrency）互不干扰；\n代码的热升级；\n\n","categories":["study"],"tags":["笔记"]},{"title":"基于软引用+Map实现Java缓存","url":"/2022/10/05/%E5%9F%BA%E4%BA%8E%E8%BD%AF%E5%BC%95%E7%94%A8+Map%E5%AE%9E%E7%8E%B0Java%E7%BC%93%E5%AD%98/","content":"\n基于软引用实现的缓存, 当内存不够使会自动释放缓存内容, 以避免OOM\n\n软引用（SoftReference）与弱引用（WeakReference）软引用：如果一个对象只具有软引用, 而当前虚拟机堆内存空间足够, 那么垃圾回收器就不会回收它, 反之就会回收这些软引用指向的对象\n弱引用：垃圾回收器一旦发现某块内存上只有弱引用（一定请注意只有弱引用, 没强引用）, 不管当前内存空间是否足够, 那么都会回收这块内存\nimport org.slf4j.Logger;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;  /** * SoftReferenceCache * * @author ape * @since 2022.10.04 */public class SoftReferenceCache&lt;K, V&gt; &#123;    private static final Logger log = org.slf4j.LoggerFactory.getLogger(&quot;c.SoftReferenceCache&quot;);    private Map&lt;K, InnerSoftReference&lt;V&gt;&gt; cache; // 缓存对象池, &lt;K, R-&gt;V&gt;    private ReferenceQueue&lt;V&gt; queue; // 引用队列, 当GC执行后被回收的缓存对象的软引用将被入队, 以方便从缓存池中清除失效的软引用。    private ReadWriteLock lock; // 读写锁    public SoftReferenceCache() &#123;        cache = new HashMap&lt;K, InnerSoftReference&lt;V&gt;&gt;();        queue = new ReferenceQueue&lt;V&gt;();        lock = new ReentrantReadWriteLock(false);    &#125;    /**     * 向缓存池中添加对象     *     * @param key     * @param value     */    public void put(K key, V value) &#123;        try &#123;            lock.writeLock().lock();            clearInvalidReference();            cache.put(key, new InnerSoftReference&lt;V&gt;(key, value, queue));        &#125; finally &#123;            lock.writeLock().unlock();        &#125;    &#125;    /**     * 从缓存池中获取对象     *     * @param key     * @return     */    public V get(K key) &#123;        try &#123;            lock.readLock().lock();            InnerSoftReference&lt;V&gt; softReference = cache.get(key);            V v = null;            if (softReference != null) v = softReference.get();            return v;        &#125; finally &#123;            lock.readLock().unlock();        &#125;    &#125;    /** 从缓存池中清除失效的软引用 备注：失效软引用是指向null的引用 */    private void clearInvalidReference() &#123;        InnerSoftReference&lt;V&gt; softReference;        while ((softReference = (InnerSoftReference) queue.poll()) != null) &#123;            if (softReference.get() == null) cache.remove(softReference.getKey());        &#125;    &#125;    /**     * 缓存池中对象的个数     *     * @return     */    public int size() &#123;        try &#123;            lock.readLock().lock();            int size = cache.size();            log.info(Thread.currentThread().getName() + &quot; 缓存池中对象的个数: &quot; + size);            return size;        &#125; finally &#123;            lock.readLock().unlock();        &#125;    &#125;    /** 清空缓存池, 定时worker每次计算前调用此方法可清除历史记录 */    public void clearCache() &#123;        try &#123;            lock.writeLock().lock();            cache = new HashMap&lt;K, InnerSoftReference&lt;V&gt;&gt;();            queue = new ReferenceQueue&lt;V&gt;();            log.info(Thread.currentThread().getName() + &quot;清空缓存池！&quot;);        &#125; finally &#123;            lock.writeLock().unlock();        &#125;    &#125;    /**     * 封装了软引用, 便于获取对应缓存池中的key     *     * @param &lt;V&gt;     */    private class InnerSoftReference&lt;V&gt; extends SoftReference&lt;V&gt; &#123;        private K key;        private InnerSoftReference(K key, V value, ReferenceQueue&lt;V&gt; queue) &#123;            super(value, queue);            this.key = key;        &#125;        public K getKey() &#123;            return key;        &#125;    &#125;&#125;\n\nimport org.slf4j.Logger;  import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;  /** * TestSoftReferenceCache * * @author ape * @since 2022.10.04 */public class TestSoftReferenceCache &#123;    private static final Logger log = org.slf4j.LoggerFactory.getLogger(&quot;c.TestSoftReferenceCache&quot;);    private static int MAX_COUNT = 1000;    private static String KEY_PREFIX = &quot;KEY_&quot;;    private static SoftReferenceCache&lt;String, byte[]&gt; cache =            new SoftReferenceCache&lt;String, byte[]&gt;();    public static void main(String[] args) &#123;        ExecutorService es = Executors.newCachedThreadPool();        es.submit(new Customer());        es.submit(new Customer());        es.submit(new Customer());        es.submit(new Customer());        es.submit(new Customer());        es.shutdown();    &#125;    static class Customer implements Runnable &#123;        @Override        public void run() &#123;            // while (true) &#123;            for (int i = 0; i &lt; MAX_COUNT; i++) &#123;                byte[] a = cache.get(KEY_PREFIX + i);                if (a == null) &#123;                    a = new byte[1024];                    cache.put(KEY_PREFIX + i, a);                    log.info(                            Thread.currentThread().getName()                                    + &quot; 向缓存池中添加对象[&quot;                                    + (KEY_PREFIX + i)                                    + &quot;]: &quot;                                    + a);                &#125; else &#123;                    log.info(                            Thread.currentThread().getName()                                    + &quot; 从缓存池中获取对象[&quot;                                    + (KEY_PREFIX + i)                                    + &quot;]: &quot;                                    + a);                &#125;            &#125;            for (int i = 0; i &lt; MAX_COUNT; i++) &#123;                byte[] a = cache.get(KEY_PREFIX + i);                if (a == null) &#123;                    a = new byte[1024];                    cache.put(KEY_PREFIX + i, a);                    log.info(                            Thread.currentThread().getName()                                    + &quot; 向缓存池中添加对象[&quot;                                    + (KEY_PREFIX + i)                                    + &quot;]: &quot;                                    + a);                &#125; else &#123;                    log.info(                            Thread.currentThread().getName()                                    + &quot; 从缓存池中获取对象[&quot;                                    + (KEY_PREFIX + i)                                    + &quot;]: &quot;                                    + a);                &#125;            &#125;            // &#125;        &#125;    &#125;&#125;\n","categories":["灵感"],"tags":["笔记"]},{"title":"并发事务的ABA问题","url":"/2022/10/09/%E5%B9%B6%E5%8F%91%E4%BA%8B%E5%8A%A1%E7%9A%84ABA%E9%97%AE%E9%A2%98/","content":"\nA 事务 (先开启), 此时 num == 0\n\nBEGINSELECT num FROM table_name where log_id =&#x27;1&#x27;-- num | 0-- 等待 事务B 执行UPDATE table_name set num = num + 1 where log_id = &#x27;1&#x27;-- 事务B 提交后, 更新成功结果 由 0 跳到 2COMMIT;\n\n\nB事物 (后开启)\n\nBEGINSELECT num FROM table_name where log_id =&#x27;1&#x27;-- num | 0UPDATE table_name set num = num + 1 where log_id = &#x27;1&#x27;-- num | 1COMMIT;\n\n\n不能成功\n\nBEGINSELECT num FROM table_name where log_id =&#x27;1&#x27;UPDATE table_name set num = num + 1 where log_id = &#x27;1&#x27; and num = 0 COMMIT;-- affect row 0\n","categories":["study"],"tags":["笔记"]}]